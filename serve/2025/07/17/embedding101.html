<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jinspire</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
     
</head>
<body>
    <main>
        <header>
            <h1>Jinspire</h1>
            <p>Writing about curiosity, insights, and reflection.</p>
            <nav class="nav-container">
                
            </nav>
        </header>

        <article class="content">
    <h1>What I learned from using 100 hours to build an embedding search engine from ground up</h1>
    <span class="date">
        
            July 17, 2025
        
    </span>

    <!-- 添加TOC切换按钮 - 根据语言显示不同文本 -->
    <button class="toc-toggle">
        Catalog
    </button>

    <!-- 添加TOC容器 -->
    <div class="toc-container" style="display: none;">
        <h4>Catalog</h4>
        <ul class="toc-list" id="toc"></ul>
    </div>

    <div class="post-content">
        
<p>I spent 100 hours to build an vector (embedding) search engine from ground up, and I ended up learning much more. I want to share what I learned, to save you some time when you need to go through a similar journey. I summarized my understanding into a <strong>brief history</strong>, and then the <strong>basic and fundamental concepts</strong>, and then share the <strong>best engineering suggestions and practices</strong> I learned.</p>

<p>TL;DR:</p>

<ul>
<li>I classify the search into <strong>3 levels</strong>: <strong>keyword search</strong>, <strong>embedding search</strong>, and <strong>agentic search</strong>.</li>

<li>I built a <strong>embedding search (semantic search engine)</strong> from ground up in 100 hours, with the goal of searching products. Keyword search can not satisfy our need for search a product using a description, where we need <strong>sematic matching</strong> (e.g., cloth vs shirt), and even <strong>multimodal information</strong> (product images, etc.).</li>

<li>Embedding, a vector representation of objects (users, products, etc.), is essentially just <strong>a list of numbers, e.g., [0.37, 0.2, 0.48, 0.4]</strong>, which <strong>condenses the information</strong> of objects (a.k.a. reduce the dimensionality of the object description). So we can use <strong>distance to measure the similarity</strong> between objects. It can be understood as a more efficient way than the old “one-hot” encoding.</li>

<li>Embedding is the <strong>backbone of LLM</strong> (e.g., word2vec). It is also the foundation of recommendation and ranking systems (basically a user embedding + item embedding -&gt; similarity score).</li>

<li>While LLM can deal with negative prompts, object embedding still <strong>can NOT deal with negative prompts yet</strong>, e.g., “not red” will be much closer to “red” than “blue”.</li>

<li>Serializing structured data into a <strong>unified string</strong> format improves accuracy, whereas embedding raw JSON syntax hurts performance.</li>

<li>My recommendated stack: <strong>PostgresSQL</strong> (traditional database) + <strong>Qwen</strong> (text embedding, and optionally reranker) + <strong>CLIP</strong> (multimodal embedding) + <strong>pgvector</strong> (vector database) + <strong>HNSW</strong> (approximate nearest neighbor algorithm) + optionally your search software for multiple rounds (hybrid elastic search, RAG, agentic search, etc.).</li>

<li>More details in the following sections.</li>
</ul>

<h2 id="brief_history_of_embedding">Brief History of Embedding</h2>

<p>I divide the history of embedding into 3 phases: <strong>keyword search</strong> (index, frequncy, inverted index), <strong>semantic search</strong> (embedding, vector database, approximate nearest neighbor algorithm), which clearly lead to <strong>hybrid search / RAG (Retrieval-Augmented Generation) / Agentic search (multi-round with LLMs)</strong>.</p>

<p><img src="/assets/images/posts/embedding101_history.jpg" alt="History of Major Milestones in Embedding" /></p>

<p>The key milestones are:</p>
<pre style="border: solid 3px red; background-color: pink" class="markdown-html-error">Maruku could not parse this XML/HTML: 
&lt;span class=&quot;color-grey&quot;&gt;**Pre-1990: Term Frequency-Inverse Document Frequency (TF-IDF) &amp; BM25**&lt;/span&gt;</pre>
<ul>
<li>Foundational statistical methods that enabled search engines to rank documents based on keyword frequency and relevance, forming the bedrock of lexical search. Kd-tree is another keyword you should know if you are interested in this topic.</li>
</ul>

<p><span class='color-grey'><strong>1996: Google PageRank</strong></span></p>

<ul>
<li>
<p>A revolutionary algorithm that determined a webpage’s importance by analyzing the quantity and quality of links pointing to it, fundamentally changing web search.</p>
</li>

<li>
<p><em><a href="https://research.google/pubs/the-anatomy-of-a-large-scale-hypertextual-web-search-engine/">Page, L., Brin, S., et al. (1998). The Anatomy of a Large-Scale Hypertextual Web Search Engine</a>.</em></p>
</li>
</ul>

<p><span class='color-grey'><strong>2010: Elasticsearch</strong></span></p>

<ul>
<li>A distributed search and analytics engine that made scalable, real-time full-text search widely accessible to developers. <em><a href="https://www.elastic.co/elasticsearch">The Elasticsearch Project site</a>.</em></li>
</ul>

<p><span class='color-blue'><strong>2013: Word2vec</strong></span></p>

<ul>
<li>
<p>A groundbreaking model that learned to represent words as numerical vectors, capturing their semantic relationships and enabling machines to understand context.</p>
</li>

<li>
<p><em><a href="https://arxiv.org/abs/1301.3781">Mikolov, T., et al. (2013). Efficient Estimation of Word Representations in Vector Space</a>.</em></p>
</li>
</ul>

<p><span class='color-green'><strong>2015: HNSW (Hierarchical Navigable Small Worlds)</strong></span></p>

<ul>
<li>
<p>A highly efficient algorithm for approximate nearest neighbor search, making it practical to find similar items in massive vector datasets almost instantly.</p>
</li>

<li>
<p><em><a href="https://arxiv.org/abs/1603.09320">Malkov, Y. A., &amp; Yashunin, D. A. (2018). Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs.</a></em></p>
</li>
</ul>

<p><span class='color-brown'><strong>2017: Transformer</strong></span></p>

<ul>
<li>
<p>A novel neural network architecture based on a self-attention mechanism, which became the foundational technology for nearly all modern large language models. Probably also need to mention BERT.</p>
</li>

<li>
<p><em><a href="https://arxiv.org/abs/1706.03762">Vaswani, A., et al. (2017). Attention Is All You Need</a>.</em></p>
</li>

<li>
<p><em><a href="https://arxiv.org/abs/1810.04805">Devlin, J., et al. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a>.</em></p>
</li>
</ul>

<p><span class='color-blue'><strong>2017: FAISS (Facebook AI Similarity Search)</strong></span></p>

<ul>
<li>
<p>A core library developed by Meta (Facebook) AI providing highly optimized algorithms for efficient similarity search and clustering of dense vectors.</p>
</li>

<li>
<p><em><a href="https://arxiv.org/abs/1702.08734">Johnson, J., Douze, M., &amp; Jégou, H. (2017). Billion-scale similarity search with GPUs</a>.</em></p>
</li>
</ul>

<p><span class='color-green'><strong>2019: pgvector</strong></span></p>

<ul>
<li>
<p>An open-source extension for the PostgreSQL database that added vector similarity search, allowing developers to combine traditional and semantic search in one system.</p>
</li>

<li>
<p><em><a href="https://github.com/pgvector/pgvector">pgvector GitHub Repository</a>.</em></p>
</li>
</ul>

<p><span class='color-green'><strong>2021: Pinecone</strong></span></p>

<ul>
<li>
<p>Established in 2019 and get public attention in 2021, Pinecone is a fully managed, cloud-native vector database designed for high-performance, large-scale similarity search in production applications. Basically a market leader for vector database, although everyone has basically caught up.</p>
</li>

<li>
<p><em><a href="https://www.pinecone.io/">Pinecone Website</a>.</em></p>
</li>
</ul>

<p><span class='color-blue'><strong>2021: CLIP (Contrastive Language–Image Pre-training)</strong></span></p>

<ul>
<li>
<p>A multi-modal model from OpenAI that connects images and text by learning from their natural language descriptions, enabling powerful cross-modal search. There is an open source version which is more or less <strong>still the state-of-the-art for image embedding</strong> (LAION-5B bigG).</p>
</li>

<li>
<p><em><a href="https://arxiv.org/abs/2103.00020">Radford, A., et al. (2021). Learning Transferable Visual Models From Natural Language Supervision</a>.</em></p>
</li>

<li>
<p><em><a href="https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k">LAION’s ViT-bigG CLIP</a>. downloaded 2 million times.</em></p>
</li>
</ul>

<p><span class='color-brown'><strong>2022: ChatGPT Moment</strong></span></p>

<ul>
<li>
<p>The public release of ChatGPT, which made advanced AI accessible to millions and triggered a massive wave of development in generative AI.</p>
</li>

<li>
<p><em><a href="https://openai.com/blog/chatgpt/">OpenAI Blog Post for ChatGPT</a>.</em></p>
</li>
</ul>

<p><span class='color-blue'><strong>2022+: Foundation Embedding Models</strong></span> &amp; <span class='color-brown'><strong>LLMs</strong></span></p>

<ul>
<li>The rapid advancement and proliferation of massive neural networks and specialized models (e.g., from OpenAI, Cohere) for generating text and creating high-quality vector embeddings.</li>
</ul>

<p><span class='color-brown'><strong>2023+: RAG (Retrieval-Augmented Generation)</strong></span></p>

<ul>
<li>
<p>While proposed in 2020, RAG became popular in 2023 with the release of GPT-3.5 and GPT-4. It is a powerful architecture that enhances LLMs by first retrieving relevant data from an external knowledge base (like a vector database) to generate more accurate answers.</p>
</li>

<li>
<p><em><a href="https://arxiv.org/abs/2005.11401">Lewis, P., et al. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.</a></em></p>
</li>
</ul>

<h2 id="basic_concepts">Basic Concepts</h2>

<p>What is embedding?</p>

<ul>
<li>A vector representation of objects (users, products, etc.).</li>

<li>It is essentially just a list of numbers, e.g., [0.37, 0.2, 0.48, 0.4].</li>

<li>It basically condenses the information of objects (a.k.a. reduce the dimensionality of the object description), so we can use distance to <strong>measure the similarity between objects</strong>. It is a more efficient way than the old “one-hot” encoding.</li>

<li>It is the <strong>backbone of LLM</strong> (e.g., word2vec). It is also the foundation of recommendation and ranking systems (basically a user embedding + item embedding -&gt; similarity score).</li>

<li>While LLM can deal with negative prompts, object embedding still can NOT deal with negative prompts, e.g., “not red” will be much closer to “red” than “blue”.</li>
</ul>

<p><strong>Cosine similarity vs Euclidean distance (L2 norm)</strong></p>

<ul>
<li>Cosine similarity is a measure of similarity between two vectors, which is the cosine of the angle between them.</li>

<li>Euclidean distance is a measure of similarity between two vectors, which is the square root of the sum of the squared differences between the two vectors.</li>

<li>Cosine similarity is more sensitive to the angle between the two vectors, while Euclidean distance is more sensitive to the magnitude of the two vectors.</li>

<li>Default to <strong>cosine similarity</strong> for embedding search.</li>
</ul>

<h2 id="model_selection">Model Selection</h2>

<ul>
<li><a href="https://huggingface.co/collections/Qwen/qwen3-embedding-6841b2055b99c44d9a4c371f">Qwen 3</a> is king, open source with good size selections. They also provide you a <a href="https://huggingface.co/collections/Qwen/qwen3-reranker-6841b22d0192d7ade9cdefea">reranker model</a>, which gives you a pairwise score if your need accuracy.</li>

<li><code>all-mpnet-base-v2</code> was the old king, but not anymore.</li>

<li>OpenAI is still a good option, and a default option for a lot of developers because of their early adoption.</li>

<li>Cohere is the startup market leader for embedding models. There is a story of <strong>Nils Reimers</strong>, who was the author of the sentence-transformer, joined Hugging Face, and then Cohere. If I name 3 most influential people in the embedding space, Nils Reimers will be one of them, together with <strong>Gerard Salton</strong> in the 1970s for the concept of <strong>vector space model (VSM)</strong> and <strong>word2vec</strong> first author <strong>Tomas Mikolov</strong>.</li>

<li>VoyageAI is another good option, which is acquired by MongoDB (2 years into 200 million) and I happen to know the CEO Tengyu Ma, a Stanford professor.</li>

<li>Gemini released an <a href="https://developers.googleblog.com/en/gemini-embedding-available-gemini-api/">embedding model</a> July 2025, which has been in experimentation since March 2025. They had terrible documentation which confused me but here is the <a href="https://ai.google.dev/gemini-api/docs/models#gemini-embedding">verified (July 2025) way to use it</a>. Also you can deploy your own embedding models using Vertex AI.</li>

<li><a href="https://huggingface.co/spaces/mteb/leaderboard">MTEB embedding leaderboard</a> is your best friend.</li>

<li>For multimodal embedding, you can use CLIP, sigCLIP, specifically, I recommend <a href="https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k">LAION-5B bigG</a>.</li>
</ul>

<h2 id="a_classic_twostage_retrieval_process_recall__rerank">A classic Two-Stage Retrieval Process: Recall + Rerank</h2>

<p>Vector search is fast but approximate. For maximum accuracy, use two stages.</p>

<ul>
<li>
<p><strong>Recall (Fast)</strong>: Use your vector database to quickly fetch a large set of candidates (e.g., the top 100). This stage is for speed and broad coverage.</p>
</li>

<li>
<p><strong>Rerank (Accurate)</strong>: Use a slower, more powerful reranker model on that small set of 100 candidates. It re-sorts them with high precision for the final result. While Qwen provides a great reranker, other classic and powerful options are worth knowing. The underlying technology is typically a cross-encoder, which processes the query and a document together for much higher accuracy than embedding similarity alone, e.g., ms-marco Models, Cohere Rerank, BERT Cross-Encoders, etc. This should give you most of the accuracy you need. If you are at a stage that 0.1% matters, you should hire a expert :-)</p>
</li>
</ul>

<p>This gives you the best of both worlds: speed across the whole dataset and high accuracy on the results you show. You can even add another middle layer, pre-rank, which is basically a simpler version of reranker.</p>

<h2 id="evaluation">Evaluation</h2>

<p>Metrics tell you if your search is actually good.</p>

<ul>
<li>
<p><strong>Precision@k</strong>: Of your top K results, how many are relevant? Measures the quality of what you show.</p>
</li>

<li>
<p><strong>Recall@k</strong>: Of all possible relevant items, how many did you find in your top K? Measures what you’re missing.</p>
</li>

<li>
<p><strong>Mean Reciprocal Rank (MRR)</strong>: What’s the rank of the first correct answer? Best for Q&amp;A or when one right answer is needed.</p>
</li>

<li>
<p><strong>Normalized Discounted Cumulative Gain (nDCG)</strong>: The gold standard. Rewards highly relevant results at the top of the list.</p>
</li>
</ul>

<h2 id="vector_databases">Vector Databases</h2>

<p>You need a vector database because a for loop to check every item is too slow. They use Approximate Nearest Neighbor (ANN) algorithms like HNSW to make search near-instant.</p>

<ul>
<li>
<p><strong>Integrated (pgvector)</strong>: Your recommended choice. Combines vectors and traditional SQL filters in one database. Simple and powerful.</p>
</li>

<li>
<p><strong>Dedicated (Pinecone, Milvus, Qdrant)</strong>: Standalone databases built for extreme scale and performance. Adds complexity but is faster for massive datasets.</p>
</li>
</ul>

<p>To build applications on top of these databases faster, many developers use additional tools. Platforms like <strong>Supabase</strong> provide a managed pgvector setup out of the box. Frameworks like <strong>LlamaIndex</strong> or <strong>LangChain</strong> offer libraries to orchestrate the entire RAG pipeline (chunking, retrieval, etc.), which saves you from writing a lot of boilerplate code.</p>

<h2 id="chunking">Chunking</h2>

<p>I didn’t encounter this issue, but it is common if you have a really big file.</p>

<ul>
<li>The key idea is <strong>don’t embed huge documents</strong>, where vector becomes a useless, blurry average of too many topics.</li>

<li>The goal is to <strong>break large text into smaller, semantically focused chunks before embedding</strong>.</li>

<li>Strategy: Start with recursive character splitting (splits by paragraph, then sentence). It’s a smart default.</li>

<li>Pro tip: Use <strong>chunk overlap</strong> (e.g., a few sentences) to maintain context between chunks.</li>
</ul>

<h2 id="future_of_search">Future of search</h2>

<p>The future is <strong>Agentic Search</strong>.</p>

<p>It’s not a single lookup. An AI agent deconstructs a complex query (“waterproof jacket under $150 with good reviews”) into a multi-step plan. This plan can involve multiple vector searches, SQL filters, and even searching within the reviews of initial results. Finally, the agent synthesizes the findings into a single, reasoned answer.</p>

<p>Search is evolving from a lookup tool into a research assistant.</p>

    </div>
</article>

<!-- 添加TOC生成和高亮脚本 -->
<script>
document.addEventListener('DOMContentLoaded', function() {
    // 获取所有标题元素
    const headings = document.querySelectorAll('.post-content h1, .post-content h2, .post-content h3, .post-content h4');
    const toc = document.getElementById('toc');
    const tocContainer = document.querySelector('.toc-container');
    const tocToggle = document.querySelector('.toc-toggle');
    const isChinesePage = false;

    // 如果没有标题，不显示TOC
    if (headings.length === 0) {
        tocToggle.style.display = 'none';
        return;
    }

    // 切换目录显示
    tocToggle.addEventListener('click', function() {
        if (tocContainer.style.display === 'none') {
            tocContainer.style.display = 'block';
            tocToggle.textContent = isChinesePage ? '关闭目录' : 'Close Catalog';
        } else {
            tocContainer.style.display = 'none';
            tocToggle.textContent = isChinesePage ? '目录' : 'Catalog';
        }
    });

    // 生成目录
    headings.forEach(function(heading, index) {
        // 为每个标题创建ID
        if (!heading.id) {
            heading.id = 'heading-' + index;
        }

        const li = document.createElement('li');
        const a = document.createElement('a');

        a.href = '#' + heading.id;
        a.textContent = heading.textContent;
        a.classList.add('toc-' + heading.tagName.toLowerCase());

        li.appendChild(a);
        toc.appendChild(li);
    });

    // 监听滚动，高亮当前标题
    const tocLinks = document.querySelectorAll('.toc-list a');

    function highlightToc() {
        let scrollPosition = window.scrollY;

        // 找到当前可见的标题
        let currentHeading = null;

        for (let i = 0; i < headings.length; i++) {
            const heading = headings[i];
            const rect = heading.getBoundingClientRect();

            // 检查标题是否在视口中或刚刚超出顶部
            if (rect.top <= 100) {
                currentHeading = heading;
            } else {
                break;
            }
        }

        // 移除所有active类
        tocLinks.forEach(link => link.classList.remove('active'));

        // 如果找到当前标题，高亮对应的TOC链接
        if (currentHeading) {
            const currentLink = document.querySelector(`.toc-list a[href="#${currentHeading.id}"]`);
            if (currentLink) {
                currentLink.classList.add('active');
            }
        }
    }

    // 初始化高亮
    highlightToc();

    // 监听滚动事件
    window.addEventListener('scroll', highlightToc);
});
</script>

        <footer>
            <p>© 2025 Jinspire · <a href="mailto:jinwu76@gmail.com">Email</a></p>
        </footer>
    </main>

    
</body>
</html>