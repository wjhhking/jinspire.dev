<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jinspire</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
     
</head>
<body>
    <main>
        <header>
            <h1>Jinspire</h1>
            <p>Writing about curiosity, insights, and reflection.</p>
            <nav class="nav-container">
                <a href="/" class="nav-link">← Back</a>
            </nav>
        </header>

        <article class="content">
    <h1>ML Resources Index</h1>
    <span class="date">
        
            May 25, 2025
        
    </span>

    <!-- 添加TOC切换按钮 - 根据语言显示不同文本 -->
    <button class="toc-toggle">
        Catalog
    </button>

    <!-- 添加TOC容器 -->
    <div class="toc-container" style="display: none;">
        <h4>Catalog</h4>
        <ul class="toc-list" id="toc"></ul>
    </div>

    <div class="post-content">
        
<p>The main purpose is to list all the resources I’ve collected about Machine Learning (ML), Artificial Intelligence (AI), and Large Language Models (LLM).</p>

<h1 id="ml_basics">ML Basics</h1>

<p>For a intro to ML, I recommend the following resources:</p>

<p>Courses: - <a href="https://developers.google.com/machine-learning/crash-course">Google Machine Learning Crash Course</a> - <a href="https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU">Stanford CS229: Machine Learning by Andrew Ng</a></p>

<p>Videos: - <a href="https://www.youtube.com/watch?v=aircAruvnKk">3Blue1Brown’s intro to neural network</a> - The youtube channel also has a lot of good videos about math (linear algebra, calculus, etc.), physics, and a lot of science topics. - <a href="https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ">Andrew Karpathy’s Neural Networks: Zero to Hero</a></p>

<p>There are many more excellent introductory materials.</p>

<h1 id="llm">LLM</h1>

<h3 id="the_two_best_courses_for_llm_are">The two best courses for LLM are:</h3>

<ul>
<li><a href="https://web.stanford.edu/class/cs224n/">Stanford CS224n</a> (winter 2025)
<ul>
<li>A very good course for a lot of intuitions for LLM with <a href="https://www.youtube.com/watch?v=rmVRLeJRkl4&list=PLoROMvodv4rMFqRtEuo6SGjY4XbRIVRd4">Youtube videos</a></li>
</ul>
</li>

<li><a href="https://stanford-cs336.github.io/spring2025/">Stanford CS336</a> (spring 2025)
<ul>
<li>The most hard-core course for LLM with <a href="https://www.youtube.com/watch?v=SQ3fZ1sAqXI&list=PLoROMvodv4rOY23Y0BoGoBGgQ1zmU_MT_">Youtube videos</a></li>
</ul>
</li>
</ul>

<h3 id="videos">Videos:</h3>

<ul>
<li>
<p><a href="https://youtu.be/t70Bl3w7bxY?si=U5EUnJ5mfV1NN-gP">Chinese: GPT 1-3 paper read by Mu Li</a></p>

<ul>
<li>A famous researcher and youtuber, who has good videos about <strong>Transformer</strong>, <strong>GPT1-4</strong>, <strong>InstructGPT</strong>, <strong>CLIP</strong>, <strong>GAN</strong>, <strong>Whisper</strong>, etc.</li>
</ul>
</li>

<li>
<p><a href="https://jax-ml.github.io/scaling-book/">Google DeepMind: How to Scale Your Model</a></p>
</li>
</ul>

<h3 id="training_infra">Training Infra</h3>

<ul>
<li><a href="https://jinspire.dev/2025/03/09/parallelism101.html">Introduction to LLM Parallelism</a>
<ul>
<li>A good introduction to the parallelism in LLM training from myself.</li>
</ul>
</li>

<li><a href="https://huggingface.co/spaces/nanotron/ultrascale-playbook?section=high-level_overview">The Ultra-Scale Playbook: Training LLMs on GPU Clusters</a> - Hugging Face’s playbook for training LLMs on GPU clusters. Very comprehensive and detailed.</li>
</ul>

<h3 id="reinforcement_learning">Reinforcement Learning</h3>

<ul>
<li><a href="http://incompleteideas.net/book/RLbook2020.pdf">RL book from Sutton and Barto</a> (2020)</li>

<li><a href="https://www.youtube.com/@ez.encoder.academy">Youtube videos from EZ.Encoder</a>
<ul>
<li>Excellent videos about <em>Deepseek</em>, <em>RL</em>, etc.</li>
</ul>
</li>
</ul>

<h3 id="interpretability">Interpretability</h3>

<ul>
<li><a href="https://arxiv.org/pdf/2111.03382">A Mathematical Framework for Transformer Circuits</a> (Dec 2021)
<ul>
<li>Anthropic’s paper conceptualizing the operation of transformers in a new but mathematically equivalent way and making sense of these small models and gain significant understanding of how they operate internally.</li>
</ul>
</li>

<li><a href="https://arxiv.org/pdf/2209.11895">In-Context Learning and Induction Heads</a> (Mar 2022)
<ul>
<li>Anthropic’s paper arguing that induction heads may be the mechanistic source of general in-context learning in transformer models of any size.</li>
</ul>
</li>

<li><a href="https://transformer-circuits.pub/2023/monosemantic-features">Towards Monosemanticity: Decomposing Language Models with Dictionary Learning</a> (Oct 2023)
<ul>
<li>Anthropic’s paper using a sparse autoencoder to extract a large number of interpretable features from a one-layer transformer.</li>
</ul>
</li>

<li><a href="https://arxiv.org/abs/2310.10348">Sparse Autoencoders Find Highly Interpretable Model Directions</a> (Oct 2023)
<ul>
<li>Using sparse autoencoders to find meaningful directions within a model’s activations.</li>
</ul>
</li>

<li><a href="https://transformer-circuits.pub/2024/scaling-monosemanticity/">Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet</a> (May 2024)
<ul>
<li>Applying and scaling these ideas to larger, more capable models like Claude 3 Sonnet.</li>
</ul>
</li>

<li><a href="https://arxiv.org/abs/2406.04093">Scaling and evaluating sparse autoencoders</a> (Jun 2024)
<ul>
<li>Exploring the practical aspects and effectiveness of sparse autoencoders at scale.</li>
</ul>
</li>

<li><a href="https://arxiv.org/abs/2406.11944">Transcoders find interpretable LLM feature circuits</a> (Jun 2024)
<ul>
<li>Focusing on finding interpretable circuits of features within LLMs.</li>
</ul>
</li>

<li><a href="https://transformer-circuits.pub/2025/attribution-graphs/biology.html">On the Biology of a Large Language Model</a> (Mar 2025)
<ul>
<li>Anthropic’s most recent paper for LLM Interpretability.</li>
</ul>
</li>
</ul>

<p>Just like you can infinite scroll on TikTok, you can infinite scroll on the papers.</p>

<h3 id="agent">Agent</h3>

<ul>
<li><a href="https://rdi.berkeley.edu/adv-llm-agents/sp25">UCB CS294/194-196 Large Language Model Agents</a>
<ul>
<li>A good course from UC Berkeley with <a href="https://www.youtube.com/live/g0Dwtf3BH-0">Youtube videos</a>, which invited a lot of frontier researchers to give lectures.</li>

<li>List of topics
<ul>
<li>Inference-Time Techniques &amp; Reasoning (CoT, ReAct, RAG, Planning, etc.)</li>

<li>Coding Agents</li>

<li>Multimodal Autonomous AI Agents</li>

<li>AlphaProof, Science Discovery</li>

<li>Reinforcement Learning</li>

<li>Safety &amp; Vulnerability</li>

<li>etc.</li>
</ul>
</li>

<li>I’m planning to write a summary for this course.</li>
</ul>
</li>
</ul>

<h3 id="">{}</h3>

<p><a href="https://jax-ml.github.io/scaling-book/inference/">All About Transformer Inference</a></p>

<h3 id="recent_llm_papers_that_i_read_and_liked">Recent LLM Papers (that I read and liked)</h3>

<p>Need to mention that a lot of the courses and resources already include a lot of good papers.</p>

<ul>
<li>Speculative deconding papers
<ul>
<li><a href="https://arxiv.org/abs/2211.17192">Fast Inference from Transformers via Speculative Decoding</a> (Nov 2022)</li>

<li><a href="https://arxiv.org/abs/2302.01318">Accelerating Large Language Model Decoding with Speculative Sampling</a> (Feb 2023)</li>

<li><a href="https://arxiv.org/abs/2310.08461">DistillSpec: Improving Speculative Decoding via Knowledge Distillation</a> (Oct 2023)</li>

<li><a href="https://arxiv.org/abs/2402.01528">Decoding Speculative Decoding</a> (Feb 2024)</li>
</ul>
</li>
</ul>

<h1 id="vision">Vision</h1>

<p>Intro: - <a href="https://jinspire.dev/2025/05/10/image101.html">Image Generation 101: an Introduction</a> A good introduction to the image generation from myself.</p>

<p>Courses: - <a href="https://cs231n.stanford.edu/">Stanfodd CS231n</a> - There seemse to be videos <a href="https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv">only from 2017</a></p>

<h3 id="papers">Papers</h3>

<ul>
<li>
<p>The intro listed a lot of important papers.</p>
</li>

<li>
<p><a href="https://arxiv.org/abs/2205.11916">Large Language Models are Zero-Shot Reasoners</a> (May 2022)</p>

<ul>
<li>The famours “Let’s think step by step” paper.</li>
</ul>
</li>
</ul>

<h1 id="news__blogs">News &amp; Blogs</h1>

<ul>
<li>
<p><a href="https://lilianweng.github.io/">Lil’Log</a></p>

<ul>
<li>Lilian Weng’s blog, ex VP of Research at OpenAI.</li>
</ul>
</li>

<li>
<p>Chinese: I usually listen to <a href="https://www.youtube.com/@bestpartners">大飞</a></p>
</li>

<li>
<p>Chinese: A good one is <a href="https://aidaily.win/">aidaily.win</a></p>
</li>

<li>
<p><a href="https://www.aiweekly.co/">AI Weekly</a></p>
</li>

<li>
<p><a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">The bitter lessons</a> Mar. 2019, Richard Sutton.</p>

<ul>
<li>The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin.</li>
</ul>
</li>

<li>
<p><a href="https://ysymyth.github.io/The-Second-Half/">The Second Half</a>, Apr. 2025, Shunyu Yao.</p>
</li>

<li>
<p><a href="https://storage.googleapis.com/deepmind-media/Era-of-Experience%20/The%20Era%20of%20Experience%20Paper.pdf">Welcome to the Era of Experience</a>, Apr. 2025, David Silver &amp; Richard Sutton, DeepMind.</p>
</li>

<li>
<p>Conciousness, strongly recommend to listen to Jeffrey Hinton’s talk in 2024.</p>

<ul>
<li><a href="https://www.youtube.com/watch?v=Es6yuMlyfPw">Will Digital Intelligence Replace Biological Intelligence</a> Nov 2024.</li>
</ul>
</li>

<li>
<p><a href="https://www.youtube.com/watch?v=Gg-w_n9NJIE&t=884s">CBMM10 Panel: Research on Intelligence in the Age of AI</a> Panel discussion of Jeffrey Hinton, Demis Hassabis, Illya Sutskever.</p>
</li>
</ul>

<h1 id="terms">Terms</h1>

<ul>
<li>Attention</li>

<li>Chain of Thought</li>

<li>Flash Attention</li>
</ul>
<hr />
<ul>
<li>ReAct</li>

<li>Transformer</li>
</ul>

<h2 id="old">Old</h2>

<ul>
<li>SIFT features: Scale-Invariant Feature Transform, old Visision method, outdated.</li>
</ul>

<h1 id="people">People</h1>

<h2 id="must_know">Must Know</h2>

<ul>
<li>
<p>Jeffrey Hinton,</p>
</li>

<li>
<p>Demis Hassabis,</p>
</li>

<li>
<p>Ilya Sutskever,</p>
</li>

<li>
<p>Yoshua Bengio,</p>
</li>

<li>
<p>Yann LeCun, Meta</p>
</li>

<li>
<p>Richard Sutton</p>
</li>

<li>
<p>Sam Altman,</p>
</li>

<li>
<p>Dario Amodei,</p>
</li>

<li>
<p>Andrew Ng,</p>
</li>

<li>
<p>Fei-Fei Li,</p>
</li>
</ul>

<h1 id="big_names">Big Names</h1>

<ul>
<li>
<p>David Silver,</p>
</li>

<li>
<p>Ian Goodfellow,</p>
</li>

<li>
<p>Andrew Karpathy</p>
</li>

<li>
<p>Jared Kaplan, Anthropic codouner and CSO.</p>
</li>

<li>
<p>Noam Shazeer</p>
</li>

<li>
<p>Kaiming He</p>
</li>

<li>
<p>Jeff Dean</p>
</li>

<li>
<p>Aidan Gomez</p>
</li>

<li>
<p>Mustafa Suleyman</p>
</li>

<li>
<p>Ashish Vaswani</p>
</li>
</ul>

    </div>
</article>

<!-- 添加TOC生成和高亮脚本 -->
<script>
document.addEventListener('DOMContentLoaded', function() {
    // 获取所有标题元素
    const headings = document.querySelectorAll('.post-content h1, .post-content h2, .post-content h3, .post-content h4');
    const toc = document.getElementById('toc');
    const tocContainer = document.querySelector('.toc-container');
    const tocToggle = document.querySelector('.toc-toggle');
    const isChinesePage = false;

    // 如果没有标题，不显示TOC
    if (headings.length === 0) {
        tocToggle.style.display = 'none';
        return;
    }

    // 切换目录显示
    tocToggle.addEventListener('click', function() {
        if (tocContainer.style.display === 'none') {
            tocContainer.style.display = 'block';
            tocToggle.textContent = isChinesePage ? '关闭目录' : 'Close Catalog';
        } else {
            tocContainer.style.display = 'none';
            tocToggle.textContent = isChinesePage ? '目录' : 'Catalog';
        }
    });

    // 生成目录
    headings.forEach(function(heading, index) {
        // 为每个标题创建ID
        if (!heading.id) {
            heading.id = 'heading-' + index;
        }

        const li = document.createElement('li');
        const a = document.createElement('a');

        a.href = '#' + heading.id;
        a.textContent = heading.textContent;
        a.classList.add('toc-' + heading.tagName.toLowerCase());

        li.appendChild(a);
        toc.appendChild(li);
    });

    // 监听滚动，高亮当前标题
    const tocLinks = document.querySelectorAll('.toc-list a');

    function highlightToc() {
        let scrollPosition = window.scrollY;

        // 找到当前可见的标题
        let currentHeading = null;

        for (let i = 0; i < headings.length; i++) {
            const heading = headings[i];
            const rect = heading.getBoundingClientRect();

            // 检查标题是否在视口中或刚刚超出顶部
            if (rect.top <= 100) {
                currentHeading = heading;
            } else {
                break;
            }
        }

        // 移除所有active类
        tocLinks.forEach(link => link.classList.remove('active'));

        // 如果找到当前标题，高亮对应的TOC链接
        if (currentHeading) {
            const currentLink = document.querySelector(`.toc-list a[href="#${currentHeading.id}"]`);
            if (currentLink) {
                currentLink.classList.add('active');
            }
        }
    }

    // 初始化高亮
    highlightToc();

    // 监听滚动事件
    window.addEventListener('scroll', highlightToc);
});
</script>

        <footer>
            <p>© 2025 Jinspire · <a href="mailto:jinwu76@gmail.com">Email</a></p>
        </footer>
    </main>

    
</body>
</html>