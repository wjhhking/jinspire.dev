<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jinspire</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
     
</head>
<body>
    <main>
        <header>
            <h1>Jinspire</h1>
            <p>Writing about curiosity, insights, and reflection.</p>
            <nav class="nav-container">
                
            </nav>
        </header>

        <article class="content">
    <h1>What are some practical implications of LLM training for my own learning process?</h1>
    <span class="date">
        
            August 25, 2025
        
    </span>

    <!-- 添加TOC切换按钮 - 根据语言显示不同文本 -->
    <button class="toc-toggle">
        Catalog
    </button>

    <!-- 添加TOC容器 -->
    <div class="toc-container" style="display: none;">
        <h4>Catalog</h4>
        <ul class="toc-list" id="toc"></ul>
    </div>

    <div class="post-content">
        
<p>I recently learned more about how large language models (LLMs) are trained, and at the same time, I began to notice parallels with my own learning process as a human. The more I thought about it, the more it seemed that the stages of LLM training mirror how we grow, work, and live.</p>

<p>Here are some of the most practical insights I found:</p>

<ul>
<li><strong>Pretraining is like schooling.</strong> It is foundational. We should keep “schooling” or pretraining ourselves, regardless of age.</li>

<li><strong>Supervised finetuning (SFT) is like working.</strong> In a job, we slightly adjust ourselves to prefer certain outputs (behaviors, deliverables) over others.</li>

<li><strong>Reinforcement learning (RL) happens all the time.</strong> We are constantly being “RLed by the world.” Rewards like dopamine hits from TikTok doomscrolling keep us hooked, while the lack of immediate rewards for saving money or exercising makes them harder to sustain.</li>
</ul>

<p>So, what are some practical implications for our own lives?</p>

<ul>
<li><strong>Embrace Lifelong Pretraining.</strong> Keep exposing yourself to new information, ideas, and perspectives — regardless of age.</li>

<li><strong>Output, don’t just read/watch/listen (encode).</strong> Teach, write, explain — that’s how knowledge sticks.</li>

<li><strong>Finetune intentionally.</strong> Seek out environments and mentors that provide the right supervision for the person you aspire to be.</li>

<li><strong>Be conscious of your reward model.</strong> If you don’t set it, the world sets it for you. And the world’s incentives (likes, clicks, quick dopamine) are rarely aligned with your deepest goals.</li>

<li><strong>Learn continually and on-demand.</strong> Shift from “learn first, then do” to “learn while doing.” Treat every task as a chance to update your model weights.</li>
</ul>

<h2 id="a_few_new_thoughts">A Few New Thoughts</h2>

<p>Some time ago, I ran a thought experiment:</p>

<p>“hought experiment: If humans were LLMs…</p>

<ul>
<li>Inventing language → Tokenization</li>

<li>Taking notes → RAG &amp; context retrieval</li>

<li>Going to school → Knowledge distillation</li>

<li>Empathy → Reading hidden states / latent embeddings</li>

<li>Dividing subjects → Mixture of Experts (MoE)</li>

<li>Creating new subjects → New tasks, loss functions, and evaluation metrics</li>
</ul>

<p>There are many more analogies from different perspectives—an interesting lens to explore!</p>

<p>“</p>

<p>Recently, I’ve been extending this analogy further:</p>

<ul>
<li>Pretraining is like schooling.</li>

<li>Working is like SFT.</li>

<li>Everyday life is constant RL.</li>

<li>Hallucination is like lying or dreaming.</li>

<li>MoE is more like brain regions than school subjects.</li>

<li>A model looping the same output is like a person getting high and repeating themselves endlessly.</li>
</ul>

<p>This lens is not perfect, but it makes us reflect: <strong>if we are like LLMs, how can we train ourselves better?</strong></p>

<h2 id="pretraining_the_foundation_of_lifelong_schooling">Pretraining: The Foundation of Lifelong Schooling</h2>

<p>Most of school life is about learning and taking exams — more or less like predicting or selecting the next token.</p>

<p>At first, it feels like rote memorization. But over time, patterns emerge and knowledge crystallizes, allowing us to master a subject and generalize beyond it.</p>

<p>AI researcher Denny Zhou has argued that reasoning ability already emerges during pretraining(<a href="https://www.youtube.com/watch?v=ebnX5Ur1hBk">link</a>). If it’s not in the pretrained base, it’s hard to acquire later. Humans are the same: without a broad foundation, it is difficult to pick up deep reasoning skills later in life.</p>

<p>That’s why pretraining is so important. In society, we even see a bias toward certain schools — similar to choosing certain base models to build on.</p>

<h2 id="supervised_finetuning_sft_adapting_in_the_workplace">Supervised Fine-Tuning (SFT): Adapting in the Workplace</h2>

<p>The work environment is like SFT.</p>

<p>Even if our base models (educational backgrounds) differ, the process of being shaped by professional expectations can change us dramatically. A workplace rewards certain responses over others — just like supervised finetuning. Over time, we learn to produce the outputs that are expected, valued, and rewarded.</p>

<p>This also suggests we should <strong>finetune intentionally</strong>: choose environments, mentors, and projects that push us in the direction we actually want to grow. This means actively seeking projects that stretch you, finding mentors who provide the ‘supervision’ you need, and even consciously adopting the communication styles of people you admire.</p>

<h2 id="reinforcement_learning_rl_navigating_the_worlds_feedback">Reinforcement Learning (RL): Navigating the World’s Feedback</h2>

<p>Every day, we are constantly being shaped by reinforcement learning. The world provides rewards and penalties for our actions, often in the form of immediate feedback loops. As Charlie Munger said, “Never, ever, think about something else when you should be thinking about the power of incentives.”</p>

<p>The most critical component of RL is the reward function. Modern life is filled with dopamine-driven reward loops that can lead us astray. We get instant rewards (dopamine hits) from watching TikTok, so we keep doomscrolling. Conversely, long-term goals like saving money or exercising offer delayed rewards, making them harder to stick with.</p>

<ul>
<li>Pavlov famously trained dogs through rewards.</li>

<li>Charlie Munger (Buffett’s longtime partner) put it bluntly:
<blockquote>
<p><em>“Show me the incentive, and I will show you the outcome.”</em></p>
</blockquote>
</li>

<li>Or in his words: <em>“Never, ever, think about something else when you should be thinking about the power of incentives.”</em></li>
</ul>

<p><strong>Reward matters.</strong></p>

<p>If our personal “reward model” is misaligned, we optimize for short-term gratification at the expense of long-term flourishing. This is reward hacking, human-style.</p>

<p>So how do we fix it? - <strong>Gamify learning.</strong> I’ve been experimenting with “additive learning”: giving myself points and badges for completing tasks, then trading those points for rewards (like phone time). It’s simple, but it works. - <strong>Identity as reinforcement.</strong> If you see yourself as a “lifelong learner,” then learning feels less like effort and more like alignment with your identity. - <strong>On-demand learning.</strong> Richard Sutton, one of the fathers of RL, proposed in his recent <a href="https://www.youtube.com/watch?v=gEbbGyNkR2U">“Oak” talk</a> that we should train directly for what is being used, instead of separating pretraining, SFT, and RL. This applies even more to humans: we learn best when the reward is tied directly to real-world use — what Andrej Karpathy calls “on-demand learning.”</p>

<p>Of course, we are not just LLMs. We have consciousness, emotions, and a rich inner world that AI doesn’t. This analogy is a map, not the territory. But like any good map, it can help us navigate the complex landscape of personal growth.</p>

<h2 id="what_are_the_implications_for_ourselves">What Are the Implications for Ourselves?</h2>

<p>Bringing it all together:</p>

<ul>
<li><strong>Embrace Lifelong Pretraining</strong> The world is too complex to rely solely on our initial schooling. We must continuously engage in broad learning to update our foundational models. Read widely, explore new domains, and stay curious. This builds the robust base needed to adapt to any future “fine-tuning” task.</li>

<li><strong>Output, don’t just read/watch/listen (encode).</strong> An encoder by itself is not enough. We can consume endless information (pretraining), but true understanding comes from generating output. This is the core of the Feynman Technique: to truly learn something, try to teach it to someone else. Writing, speaking, and creating are how we distill knowledge and expose the gaps in our thinking.</li>

<li><strong>Finetune intentionally.</strong> Don’t just let work or culture shape you passively. Choose environments that reinforce what you want to become. Learn from the greatest.</li>

<li><strong>Be conscious of your reward model.</strong> Don’t let the world’s default reward functions dictate your behavior. Consciously define your long-term goals and create immediate, tangible rewards for the actions that lead to them. Align your habits with your identity to make positive behaviors feel natural and effortless.</li>

<li><strong>Learn continually and on-demand.</strong> Shift your mindset from a “learn-then-do” model to a “learn-while-doing” one. Treat every task as an opportunity to update your skills. When you encounter a problem, dive deep into the necessary knowledge right then and there. This makes learning relevant and immediately applicable, effectively updating your mental model in real-time.</li>
</ul>

<p>These ideas aren’t just theoretical for me. They’ve inspired me to build tools to help put them into practice, starting with an app I’m developing called ‘Human Pretraining’ and I’m excited to share it with you soon.</p>

    </div>
</article>

<!-- 添加TOC生成和高亮脚本 -->
<script>
document.addEventListener('DOMContentLoaded', function() {
    // 获取所有标题元素
    const headings = document.querySelectorAll('.post-content h1, .post-content h2, .post-content h3, .post-content h4');
    const toc = document.getElementById('toc');
    const tocContainer = document.querySelector('.toc-container');
    const tocToggle = document.querySelector('.toc-toggle');
    const isChinesePage = false;

    // 如果没有标题，不显示TOC
    if (headings.length === 0) {
        tocToggle.style.display = 'none';
        return;
    }

    // 切换目录显示
    tocToggle.addEventListener('click', function() {
        if (tocContainer.style.display === 'none') {
            tocContainer.style.display = 'block';
            tocToggle.textContent = isChinesePage ? '关闭目录' : 'Close Catalog';
        } else {
            tocContainer.style.display = 'none';
            tocToggle.textContent = isChinesePage ? '目录' : 'Catalog';
        }
    });

    // 生成目录
    headings.forEach(function(heading, index) {
        // 为每个标题创建ID
        if (!heading.id) {
            heading.id = 'heading-' + index;
        }

        const li = document.createElement('li');
        const a = document.createElement('a');

        a.href = '#' + heading.id;
        a.textContent = heading.textContent;
        a.classList.add('toc-' + heading.tagName.toLowerCase());

        li.appendChild(a);
        toc.appendChild(li);
    });

    // 监听滚动，高亮当前标题
    const tocLinks = document.querySelectorAll('.toc-list a');

    function highlightToc() {
        let scrollPosition = window.scrollY;

        // 找到当前可见的标题
        let currentHeading = null;

        for (let i = 0; i < headings.length; i++) {
            const heading = headings[i];
            const rect = heading.getBoundingClientRect();

            // 检查标题是否在视口中或刚刚超出顶部
            if (rect.top <= 100) {
                currentHeading = heading;
            } else {
                break;
            }
        }

        // 移除所有active类
        tocLinks.forEach(link => link.classList.remove('active'));

        // 如果找到当前标题，高亮对应的TOC链接
        if (currentHeading) {
            const currentLink = document.querySelector(`.toc-list a[href="#${currentHeading.id}"]`);
            if (currentLink) {
                currentLink.classList.add('active');
            }
        }
    }

    // 初始化高亮
    highlightToc();

    // 监听滚动事件
    window.addEventListener('scroll', highlightToc);
});
</script>

        <footer>
            <p>© 2025 Jinspire · <a href="mailto:jinwu76@gmail.com">Email</a></p>
        </footer>
    </main>

    
</body>
</html>